---
layout: page
permalink: /teaching/
title: teaching
description: Materials and reflections from courses I have taught and supported.
nav: true
nav_order: 6
---

# Dartmouth College  
### Spring 2025 — COSC 55: Security & Privacy  
**Role: PhD Graduate Teaching Assistant (with Prof. Sami Saydjari)**  

![Teaching session]({{ '/assets/img/prof_sami.jpg' | relative_url }})

This spring at Dartmouth College, I had the chance to serve as a (Lead) Graduate Teaching Assistant for COSC 55: Security & Privacy with the incredible Prof. Sami Saydjari—and it turned out to be one of the most transformative experiences of my academic journey.  

It wasn’t just about supporting a course.  
It was about reimagining how we teach Computer Science in a world where tools like ChatGPT and GitHub Copilot are always just a click away.  

I came into this role with a belief that guided everything I did:  
**AI is reshaping how students learn—and our teaching must evolve with it.**  

Instead of pretending students weren’t using these tools, I leaned in. I redesigned part of the course to embrace AI coding assistants—while holding students to a higher standard of understanding.  

I created a new set of labs where:  
✅ Students had full freedom in system design  
✅ AI tools were allowed—but used mindfully  
✅ Every week, I met each student/team for oral check-ins to probe real understanding  
✅ Each project ended with a final oral evaluation  

If you used AI, great—but you had to explain, justify, and defend your choices.  


This wasn’t about catching anyone—it was about preparing students to think like engineers, not just produce output.  
I learned that it’s not enough to ask what students built—we have to keep asking *why* until they own their thinking.  

I decided to take full ownership of this new model:  
 • 28 students  
 • Weekly 1-on-1s  
 • All lab design, grading, and evaluations  
It was a heavy lift—far beyond the usual expectations.  

One of their standout projects was **WhisperChain+**—a secure, anonymous compliment system with:  
🔐 Role-based control  
🔐 Blind signature tokens  
🔐 Privacy-preserving audit logs  
It was ambitious, messy, and beautifully real.  


After a final oral evaluation, a student told me:  
> “This is the best way to force real understanding. I wish more courses at Dartmouth did this.”  

That one sentence made my whole term.  

Then came the anonymous feedback—filled with honesty, kindness, and deep appreciation. Reading them all was genuinely overwhelming—in the best possible way.  

None of this would’ve been possible without Prof. Sami Saydjari, who treated me not as a TA but as a co-teacher.  
His trust gave me the space to build something I believed in—and I’ll always be grateful for that.  

Now the term is over. I’ve watched teams evolve from “Which hash function do we use?” to debating zero-knowledge proofs and user-experience trade-offs.  
And I’ve walked away convinced that the future of Computer Science education is:  
**AI-enabled, yet deeply human—built on conversation, reflection, and the courage to demand understanding over syntax.**  

To my students: You challenged me, and you grew with me. I’ll carry this term with me for a long time.  

To fellow educators: The future is already here. **AI belongs in the classroom—but so does rigor, reflection, and humanity.**

[Check out my LinkedIn post](https://www.linkedin.com/posts/mohamedmostafadawod_cybersecurity-aiineducation-privacy-activity-7338998254958764035-AywP?utm_source=share&utm_medium=member_desktop&rcm=ACoAADFQmcoBLJ38qGoOSyAVBnbdTFJ_37jmCls)


![Teaching session]({{ '/assets/img/teaching_2.jpg' | relative_url }})
![Teaching session]({{ '/assets/img/teaching_1.jpg' | relative_url }})
